---
layout: publication
year: 2024
title: "The Impact of Imperfect XAI on Human-AI Decision-Making"
authors:
  - Katelyn Morrison
  - Philipp Spitzer
  - Violet Turri
  - Michelle Feng
  - Niklas KÃ¼hl
  - Adam Perer
venue: CSCW
venue_location: San Jose, Costa Rica
venue_tags:
  - CSCW
venue_url: https://cscw.acm.org/2024/
pdf: https://arxiv.org/pdf/2307.13566.pdf
highlight: true
type:
  - Conference
tags:
  - Machine Learning
  - Explainable AI
  - Human-AI Collaboration
---

Explainability techniques are rapidly being developed to improve human-AI
decision-making across various cooperative work settings. Consequently, previous
research has evaluated how decision-makers collaborate with imperfect AI by
investigating appropriate reliance and task performance with the aim of
designing more human-centered computer-supported collaborative tools. Several
human-centered explainable AI (XAI) techniques have been proposed in hopes of
improving decision-makers' collaboration with AI; however, these techniques are
grounded in findings from previous studies that primarily focus on the impact of
incorrect AI advice. Few studies acknowledge the possibility of the explanations
being incorrect even if the AI advice is correct. Thus, it is crucial to
understand how imperfect XAI affects human-AI decision-making. In this work, we
contribute a robust, mixed-methods user study with 136 participants to evaluate
how incorrect explanations influence humans' decision-making behavior in a bird
species identification task, taking into account their level of expertise and an
explanation's level of assertiveness. Our findings reveal the influence of
imperfect XAI and humans' level of expertise on their reliance on AI and
human-AI team performance. We also discuss how explanations can deceive
decision-makers during human-AI collaboration. Hence, we shed light on the
impacts of imperfect XAI in the field of computer-supported cooperative work and
provide guidelines for designers of human-AI collaboration systems.
